{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datast 1 : Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset we will explore how our plumber optimizer performs on a simple binary classification task with a relatively small dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "import time\n",
    "import psutil\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importinng the PlumberOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from Plumber import PlumberOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data and performing feature engineering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values for Age, Embarked, and Fare with median or mode\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "train_data['Age'] = train_data['Age'].fillna(train_data['Age'].median())\n",
    "train_data['Embarked'] = train_data['Embarked'].fillna(train_data['Embarked'].mode()[0])\n",
    "train_data['Fare'] = train_data['Fare'].fillna(train_data['Fare'].median())\n",
    "\n",
    "train_data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "\n",
    "# Encode categorical variables Sex and Embarked using label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "train_data['Sex'] = label_encoder.fit_transform(train_data['Sex'])\n",
    "train_data['Embarked'] = label_encoder.fit_transform(train_data['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into features X and target y, and performing a train-test split\n",
    "X = train_data.drop(\"Survived\", axis=1)\n",
    "y = train_data[\"Survived\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the performance and efficiency of the PlumberOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A single model takes  0.07239675521850586 seconds to run\n",
      "Suggested number of trails is 150 \n",
      "Best Parameters: {'n_estimators': 50, 'max_depth': 25, 'min_samples_split': 18, 'min_samples_leaf': 6, 'max_features': 'sqrt'}\n",
      "Best Score: 0.8314777387748348\n",
      "A single model takes  0.04865002632141113 seconds to run\n",
      "Suggested number of trails is 150 \n",
      "Best Parameters: {'n_estimators': 100, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Best Score: 0.8300771785507451\n",
      "A single model takes  0.047035932540893555 seconds to run\n",
      "Suggested number of trails is 150 \n",
      "Best Parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 13, 'min_samples_leaf': 2, 'max_features': 'sqrt'}\n",
      "Best Score: 0.8300476308666926\n",
      "A single model takes  0.0494990348815918 seconds to run\n",
      "Suggested number of trails is 150 \n",
      "Best Parameters: {'n_estimators': 50, 'max_depth': 25, 'min_samples_split': 12, 'min_samples_leaf': 5, 'max_features': 'log2'}\n",
      "Best Score: 0.827252419955324\n",
      "A single model takes  0.05258488655090332 seconds to run\n",
      "Suggested number of trails is 150 \n",
      "Best Parameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': 'log2'}\n",
      "Best Score: 0.8300653594771242\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*************\n",
      "Execution Time: mean=19.00 seconds, std=4.148381628959285 seconds, max=23.815764904022217 seconds, min=11.55355191230774 seconds\n",
      "CPU Usage: mean=9.66%, std=1.11%, max=10.70%, min=7.70%\n",
      "Memory Usage: mean=5.96 MB, std=1.32 MB, max=7.38 MB, min=3.59 MB\n",
      "Validation Score: mean=0.8268156424581005 , std=0.011718534616426272 , max=0.8491620111731844 , min=0.8156424581005587 \n"
     ]
    }
   ],
   "source": [
    "# Arrays to store execution times, memory usage, CPU usage, and evaluatin scores\n",
    "plumber_time = np.zeros(5,'float')\n",
    "plumber_mem = np.zeros(5,'float')\n",
    "plumber_cpu =  np.zeros(5,'float')\n",
    "plumber_score = np.zeros(5,'float')\n",
    "for i in range(5):\n",
    "    opt = PlumberOptimizer(X_train, y_train)\n",
    "\n",
    "    # Monitor the current process, record the start time, initial CPU usage, and memory usage in MB\n",
    "    process = psutil.Process(os.getpid())\n",
    "    start_time = time.time()\n",
    "    start_cpu = process.cpu_percent(interval=None)\n",
    "    start_mem = process.memory_info().rss / (1024 * 1024) \n",
    "\n",
    "\n",
    "    best = opt.optimize()\n",
    "\n",
    "    end_time = time.time()\n",
    "    end_cpu = process.cpu_percent(interval=None)\n",
    "    end_mem = process.memory_info().rss / (1024 * 1024)  \n",
    "\n",
    "    # Calculating execution time, memory usage, and CPU usage\n",
    "    plumber_time[i] = end_time - start_time\n",
    "    plumber_mem[i] = end_mem - start_mem\n",
    "    plumber_cpu[i] = end_cpu - start_cpu\n",
    "\n",
    "    # Training and evaluating the model using the best parameters\n",
    "    rf = RandomForestClassifier(**best , random_state=42 )\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "\n",
    "    plumber_score[i] = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# summary for the Plumber Optimizer\n",
    "print(\"\\n\" *3)\n",
    "print(\"*************\")\n",
    "print(f\"Execution Time: mean={np.mean(plumber_time):.2f} seconds, std={np.std(plumber_time)} seconds, max={np.max(plumber_time)} seconds, min={np.min(plumber_time)} seconds\")\n",
    "print(f\"CPU Usage: mean={np.mean(plumber_cpu):.2f}%, std={np.std(plumber_cpu):.2f}%, max={np.max(plumber_cpu):.2f}%, min={np.min(plumber_cpu):.2f}%\")\n",
    "print(f\"Memory Usage: mean={np.mean(plumber_mem):.2f} MB, std={np.std(plumber_mem):.2f} MB, max={np.max(plumber_mem):.2f} MB, min={np.min(plumber_mem):.2f} MB\")\n",
    "print(f\"Validation Score: mean={np.mean(plumber_score)} , std={np.std(plumber_score)} , max={np.max(plumber_score)} , min={np.min(plumber_score)} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the performance and efficiency of the GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time: 112.49 seconds\n",
      "CPU Usage: 3.90%\n",
      "Memory Usage: 1.28 MB\n",
      "Validation Accuracy: 0.8212290502793296\n",
      "{'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 12, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/ma/core.py:2881: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    }
   ],
   "source": [
    "# Defining GridSearch parameters\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],  \n",
    "    'max_features': ['sqrt', 'log2'],  \n",
    "    'max_depth': [10, 20, 30, 40, 50],  \n",
    "    'min_samples_split': [2, 5, 10, 12, 16, 20], \n",
    "    'min_samples_leaf': [2, 5, 6, 8,12,16, 20]  \n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "# Monitor the current process, record the start time, initial CPU usage, and memory usage in MB\n",
    "process = psutil.Process(os.getpid())\n",
    "start_time = time.time()\n",
    "start_cpu = process.cpu_percent(interval=None)\n",
    "start_mem = process.memory_info().rss / (1024 * 1024)  \n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "end_cpu = process.cpu_percent(interval=None)\n",
    "end_mem = process.memory_info().rss / (1024 * 1024) \n",
    "\n",
    "# Print metrics for GridSearch\n",
    "print(f\"Execution Time: {end_time - start_time:.2f} seconds\")\n",
    "print(f\"CPU Usage: {end_cpu - start_cpu:.2f}%\")\n",
    "print(f\"Memory Usage: {end_mem - start_mem:.2f} MB\")\n",
    "\n",
    "\n",
    "# Training the model with the best parameters and evaluate\n",
    "rf = RandomForestClassifier(** grid_search.best_params_, random_state=42 )\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Validation Accuracy: {accuracy}\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the performance and efficiency of the RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/ma/core.py:2881: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time: mean=11.76 seconds, std=0.5812654769689958 seconds, max=12.347316980361938 seconds, min=10.799278736114502 seconds\n",
      "CPU Usage: mean=4.94%, std=0.57%, max=5.30%, min=3.80%\n",
      "Memory Usage: mean=0.08 MB, std=0.08 MB, max=0.23 MB, min=0.00 MB\n",
      "Validation Score: mean=0.8201117318435754 , std=0.002234636871508355 , max=0.8212290502793296 , min=0.8156424581005587 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/ma/core.py:2881: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    }
   ],
   "source": [
    "# Defining the parameter for RandomizedSearch\n",
    "param_dist = {\n",
    "    'n_estimators': np.arange(50, 500),\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'max_depth': np.arange(10, 31),\n",
    "    'min_samples_split': np.arange(2, 50),\n",
    "    'min_samples_leaf': np.arange(1, 50)\n",
    "}\n",
    "# Arrays to store execution times, memory usage, CPU usage, and evaluation scores\n",
    "rand_time = np.zeros(5,'float')\n",
    "rand_mem = np.zeros(5,'float')\n",
    "rand_cpu =  np.zeros(5,'float')\n",
    "rand_score = np.zeros(5,'float')\n",
    "for i in range(5):\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist,\n",
    "                                    n_iter=250, cv=3, n_jobs=-1)\n",
    "    \n",
    "    # Monitor the current process, record the start time, initial CPU usage, and memory usage in MB\n",
    "    process = psutil.Process(os.getpid())\n",
    "    start_time = time.time()\n",
    "    start_cpu = process.cpu_percent(interval=None)\n",
    "    start_mem = process.memory_info().rss / (1024 * 1024)  \n",
    "\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    end_time = time.time()\n",
    "    end_cpu = process.cpu_percent(interval=None)\n",
    "    end_mem = process.memory_info().rss / (1024 * 1024)  \n",
    "\n",
    "    # Calculating execution time, memory usage, and CPU usage\n",
    "    rand_time[i] = end_time - start_time\n",
    "    rand_mem[i] = end_mem - start_mem\n",
    "    rand_cpu[i] = end_cpu - start_cpu\n",
    "\n",
    "    # Training the model with the best parameters and evaluate\n",
    "    rf = RandomForestClassifier(** random_search.best_params_ , random_state=42 )\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "\n",
    "    rand_score[i] = accuracy_score(y_test, y_pred)\n",
    "\n",
    "#RandomizedSearchCV results\n",
    "print(f\"Execution Time: mean={np.mean(rand_time):.2f} seconds, std={np.std(rand_time)} seconds, max={np.max(rand_time)} seconds, min={np.min(rand_time)} seconds\")\n",
    "print(f\"CPU Usage: mean={np.mean(rand_cpu):.2f}%, std={np.std(rand_cpu):.2f}%, max={np.max(rand_cpu):.2f}%, min={np.min(rand_cpu):.2f}%\")\n",
    "print(f\"Memory Usage: mean={np.mean(rand_mem):.2f} MB, std={np.std(rand_mem):.2f} MB, max={np.max(rand_mem):.2f} MB, min={np.min(rand_mem):.2f} MB\")\n",
    "print(f\"Validation Score: mean={np.mean(rand_score)} , std={np.std(rand_score)} , max={np.max(rand_score)} , min={np.min(rand_score)} \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the performance and efficiency of the BayesSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "Execution Time: mean=39.47 seconds, std=1.453007841539628 seconds, max=41.74519991874695 seconds, min=38.180853843688965 seconds\n",
      "CPU Usage: mean=79.22%, std=1.75%, max=81.40%, min=76.10%\n",
      "Memory Usage: mean=39.67 MB, std=68.11 MB, max=175.31 MB, min=0.00 MB\n",
      "Validation Score: mean=0.8201117318435754 , std=0.008938547486033491 , max=0.8324022346368715 , min=0.8044692737430168 \n"
     ]
    }
   ],
   "source": [
    "# Define the parameter for BayesSearchCV\n",
    "param_dist = {\n",
    "    'n_estimators': Integer(50, 500),\n",
    "    'max_features': Categorical(['sqrt', 'log2']),\n",
    "    'max_depth': Integer(10, 50),\n",
    "    'min_samples_split': Integer(2, 50),\n",
    "    'min_samples_leaf': Integer(1, 50)\n",
    "}\n",
    "# Arrays to store execution times, memory usage, CPU usage, and evaluation scores\n",
    "rand_time = np.zeros(5,'float')\n",
    "rand_mem = np.zeros(5,'float')\n",
    "rand_cpu =  np.zeros(5,'float')\n",
    "rand_score = np.zeros(5,'float')\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    bayes_search = BayesSearchCV(estimator=rf, search_spaces=param_dist,\n",
    "                             n_iter=70, cv=3, n_jobs=-1)\n",
    "\n",
    "    # Monitor the current process, record the start time, initial CPU usage, and memory usage in MB\n",
    "    process = psutil.Process(os.getpid())\n",
    "    start_time = time.time()\n",
    "    start_cpu = process.cpu_percent(interval=None)\n",
    "    start_mem = process.memory_info().rss / (1024 * 1024) \n",
    "\n",
    "    bayes_search.fit(X_train, y_train)\n",
    "\n",
    "    end_time = time.time()\n",
    "    end_cpu = process.cpu_percent(interval=None)\n",
    "    end_mem = process.memory_info().rss / (1024 * 1024)  \n",
    "\n",
    "    # Calculating execution time, memory usage, and CPU usage\n",
    "    rand_time[i] = end_time - start_time\n",
    "    rand_mem[i] = end_mem - start_mem\n",
    "    rand_cpu[i] = end_cpu - start_cpu\n",
    "\n",
    "    # Training the model with the best parameters and evaluate\n",
    "    rf = RandomForestClassifier(** bayes_search.best_params_ , random_state=42 )\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "\n",
    "    rand_score[i] = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "# BayesSearchCV results\n",
    "print(f\"Execution Time: mean={np.mean(rand_time):.2f} seconds, std={np.std(rand_time)} seconds, max={np.max(rand_time)} seconds, min={np.min(rand_time)} seconds\")\n",
    "print(f\"CPU Usage: mean={np.mean(rand_cpu):.2f}%, std={np.std(rand_cpu):.2f}%, max={np.max(rand_cpu):.2f}%, min={np.min(rand_cpu):.2f}%\")\n",
    "print(f\"Memory Usage: mean={np.mean(rand_mem):.2f} MB, std={np.std(rand_mem):.2f} MB, max={np.max(rand_mem):.2f} MB, min={np.min(rand_mem):.2f} MB\")\n",
    "print(f\"Validation Score: mean={np.mean(rand_score)} , std={np.std(rand_score)} , max={np.max(rand_score)} , min={np.min(rand_score)} \")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
